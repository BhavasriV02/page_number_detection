# -*- coding: utf-8 -*-
"""Pagenumber detection yolov8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14xJ8TDnye-DP2y1XBUW1ChSYgHiPOdEM
"""

from ultralytics import YOLO

dataset_path = "/content/drive/MyDrive/yolov8page number/data.yaml"


model = YOLO("yolov8n.pt")


model.train(data=dataset_path, epochs=100, imgsz=640, batch=8, device="cuda")


model_path = "/content/runs/detect/train/weights/best.pt"

!pip install ultralytics

import pandas as pd
import matplotlib.pyplot as plt


results_csv_path = "/content/runs/detect/train2/results.csv"


results_df = pd.read_csv(results_csv_path)

print("Available columns:", results_df.columns)

metrics = ["train/box_loss", "train/cls_loss", "train/dfl_loss", "metrics/mAP_50"]


for metric in metrics:
    if metric in results_df.columns:
        plt.figure(figsize=(10, 5))
        plt.plot(results_df["epoch"], results_df[metric], label=metric, marker="o")
        plt.xlabel("Epoch")
        plt.ylabel(metric)
        plt.title(f"Training Progress: {metric}")
        plt.legend()
        plt.grid(True)
        plt.show()
    else:
        print(f"Metric '{metric}' not found in results.csv")

!pip install ultralytics

# prompt: give code to find the evaluation metrics of this model line precision,accuracy,f1 score,recall,etc

from ultralytics import YOLO
import pandas as pd

# Assuming 'results.csv' is in the correct location
results_csv_path = "/content/drive/MyDrive/yolov8_pagenumber/train2/results.csv"

try:
    results_df = pd.read_csv(results_csv_path)

    # Access metrics (replace with actual column names if different)
    if "metrics/precision(B)" in results_df.columns:
        precision = results_df["metrics/precision(B)"].iloc[-1]  # Get the last value
        print(f"Precision: {precision}")
    else:
        print("Precision metric not found.")

    if "metrics/recall(B)" in results_df.columns:
        recall = results_df["metrics/recall(B)"].iloc[-1]
        print(f"Recall: {recall}")
    else:
        print("Recall metric not found.")

    if "metrics/mAP50-95(B)" in results_df.columns:
      map50_95 = results_df["metrics/mAP50-95(B)"].iloc[-1]
      print(f"mAP50-95: {map50_95}")
    else:
      print("mAP50-95 metric not found.")

    if "metrics/F1(B)" in results_df.columns:
        f1 = results_df["metrics/F1(B)"].iloc[-1]
        print(f"F1-score: {f1}")
    else:
        print("F1-score metric not found.")


    # ... (add other metrics similarly)

except FileNotFoundError:
    print(f"Error: results.csv not found at {results_csv_path}")
except Exception as e:
    print(f"An error occurred: {e}")

# Given Precision and Recall values
precision = 0.86589
recall = 0.79991

# Compute F1-score
f1_score = (2 * precision * recall) / (precision + recall)

# Print result
print(f"F1-score: {f1_score:.5f}")

from ultralytics import YOLO

model = YOLO("/content/drive/MyDrive/yolov8_pagenumber/train2/weights/best.pt")


results = model.predict(source="/content/testcase1.JPG", save=True)

results[0].show()

model = YOLO("/content/drive/MyDrive/yolov8_pagenumber/train2/weights/best.pt")

results = model.predict(source="/content/testcase2.JPG", save=True)

results[0].show()

model = YOLO("/content/drive/MyDrive/yolov8_pagenumber/train2/weights/best.pt")  # Update with correct path

results = model.predict(source="/content/04_02_2023_17_02_322_page_33_png.rf.c7330749a56ba9df592d4c3eaa9a176d.jpg", conf=0.25, iou=0.5, save=True)

results[0].show()

import locale
def getpreferredencoding(do_setlocale = True):
    return "UTF-8"
locale.getpreferredencoding = getpreferredencoding
!cp -r /content/runs/detect /content/drive/MyDrive/yolov8_pagenumber/

!pip install pytesseract

!sudo apt install tesseract-ocr
!sudo apt install libtesseract-dev

import cv2
import numpy as np
import pytesseract
from ultralytics import YOLO
from google.colab.patches import cv2_imshow  # For Colab image display

# Load YOLO model
model = YOLO("/content/drive/MyDrive/yolov8_pagenumber/train2/weights/best.pt")

# Perform prediction
results = model.predict(source="/content/testcase2.JPG", save=True)

# Load the image
image_path = "/content/testcase2.JPG"
image = cv2.imread(image_path)

# Loop through detections
for result in results:
    for i, box in enumerate(result.boxes):
        x1, y1, x2, y2 = map(int, box.xyxy[0])  # Get bounding box coordinates
        cropped = image[y1:y2, x1:x2]  # Crop detected region

        # Convert to grayscale and apply thresholding for better OCR detection
        gray = cv2.cvtColor(cropped, cv2.COLOR_BGR2GRAY)
        thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]

        # Use OCR to extract text
        page_number = pytesseract.image_to_string(thresh, config='--psm 7').strip()

        # Debug: Print extracted text
        print(f"Detected Page Number {i+1}: {page_number}")

        # Draw bounding box
        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)

        # Display extracted text on the image
        cv2.putText(image, page_number, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX,
                    0.6, (0, 255, 0), 2)

# Show final image with bounding boxes & text
cv2_imshow(image)

import cv2
import numpy as np
import pytesseract
from ultralytics import YOLO
from google.colab.patches import cv2_imshow  # For Colab image display

# Load YOLO model
model = YOLO("/content/drive/MyDrive/yolov8_pagenumber/train2/weights/best.pt")

# Perform prediction
results = model.predict(source="/content/testcase2.JPG", save=True)

# Load the image
image_path = "/content/testcase2.JPG"
image = cv2.imread(image_path)

best_page_number = ""  # Store the final extracted page number
best_confidence = 0.0  # Track the best confidence score

for result in results:
    for box in result.boxes:
        x1, y1, x2, y2 = map(int, box.xyxy[0])  # Get bounding box coordinates
        confidence = box.conf[0].item()  # Get confidence score

        cropped = image[y1:y2, x1:x2]  # Crop detected region

        # Convert to grayscale and apply thresholding for better OCR detection
        gray = cv2.cvtColor(cropped, cv2.COLOR_BGR2GRAY)
        thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]

        # Use OCR to extract text
        page_number = pytesseract.image_to_string(thresh, config='--psm 7').strip()

        # Check if OCR detected a meaningful number
        if page_number.isdigit() and confidence > best_confidence:
            best_page_number = page_number
            best_confidence = confidence

# Display the best detected page number
if best_page_number:
    print(f"Final Detected Page Number: {best_page_number}")
else:
    print("No valid page number detected.")

# Show image with bounding box
cv2_imshow(image)

import cv2
import numpy as np
import pytesseract
from ultralytics import YOLO
from google.colab.patches import cv2_imshow  # For Colab image display

# Load YOLO model
model = YOLO("/content/drive/MyDrive/yolov8_pagenumber/train2/weights/best.pt")

# Perform prediction
results = model.predict(source="/content/testcase1.JPG", save=True)

# Load the image
image_path = "/content/testcase1.JPG"
image = cv2.imread(image_path)

best_page_number = ""  # Store the final extracted page number
best_confidence = 0.0  # Track the best confidence score

for result in results:
    for box in result.boxes:
        x1, y1, x2, y2 = map(int, box.xyxy[0])  # Get bounding box coordinates
        confidence = box.conf[0].item()  # Get confidence score

        cropped = image[y1:y2, x1:x2]  # Crop detected region

        # Convert to grayscale and apply thresholding for better OCR detection
        gray = cv2.cvtColor(cropped, cv2.COLOR_BGR2GRAY)
        thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]

        # Use OCR to extract text
        page_number = pytesseract.image_to_string(thresh, config='--psm 7').strip()

        # Check if OCR detected a meaningful number
        if page_number.isdigit() and confidence > best_confidence:
            best_page_number = page_number
            best_confidence = confidence

# Display the best detected page number
if best_page_number:
    print(f"Final Detected Page Number: {best_page_number}")
else:
    print("No valid page number detected.")

# Show image with bounding box
cv2_imshow(image)

import cv2
import numpy as np
import pytesseract
from ultralytics import YOLO
from google.colab.patches import cv2_imshow  # For Colab image display

# Load YOLO model
model = YOLO("/content/drive/MyDrive/yolov8_pagenumber/train2/weights/best.pt")

# Perform prediction
results = model.predict(source="/content/04_02_2023_17_02_322_page_33_png.rf.c7330749a56ba9df592d4c3eaa9a176d.jpg", save=True)

# Load the image
image_path = "/content/04_02_2023_17_02_322_page_33_png.rf.c7330749a56ba9df592d4c3eaa9a176d.jpg"
image = cv2.imread(image_path)

best_page_number = ""  # Store the final extracted page number
best_confidence = 0.0  # Track the best confidence score

for result in results:
    for box in result.boxes:
        x1, y1, x2, y2 = map(int, box.xyxy[0])  # Get bounding box coordinates
        confidence = box.conf[0].item()  # Get confidence score

        cropped = image[y1:y2, x1:x2]  # Crop detected region

        # Convert to grayscale and apply thresholding for better OCR detection
        gray = cv2.cvtColor(cropped, cv2.COLOR_BGR2GRAY)
        thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]

        # Use OCR to extract text
        page_number = pytesseract.image_to_string(thresh, config='--psm 7').strip()

        # Check if OCR detected a meaningful number
        if page_number.isdigit() and confidence > best_confidence:
            best_page_number = page_number
            best_confidence = confidence

# Display the best detected page number
if best_page_number:
    print(f"Final Detected Page Number: {best_page_number}")
else:
    print("No valid page number detected.")

# Show image with bounding box
cv2_imshow(image)

!pip install easyocr

!pip install easyocr ultralytics opencv-python pytesseract

!pip install paddleocr

!pip install paddlepaddle

import cv2
import numpy as np
from paddleocr import PaddleOCR
from ultralytics import YOLO
from google.colab.patches import cv2_imshow  # For Colab image display

# Load YOLO model (Ensure you have the correct model path)
model = YOLO("/content/drive/MyDrive/yolov8_pagenumber/train2/weights/best.pt")

# Initialize PaddleOCR for handwritten text (English)
ocr = PaddleOCR(lang="en", use_angle_cls=True, rec_algorithm='CRNN')

# Load the image
image_path = "/content/04_02_2023_17_02_322_page_33_png.rf.c7330749a56ba9df592d4c3eaa9a176d.jpg"
image = cv2.imread(image_path)

# Perform YOLO prediction
results = model.predict(source=image_path)

best_page_number = ""  # Store the final extracted page number
best_confidence = 0.0  # Track the best confidence score

# Process each detected bounding box
for result in results:
    for box in result.boxes:
        x1, y1, x2, y2 = map(int, box.xyxy[0])  # Bounding box coordinates
        confidence = box.conf[0].item()  # YOLO confidence score

        # Draw bounding box on the image
        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Green box

        # Crop the detected bounding box from the image
        cropped = image[y1:y2, x1:x2]

        # Convert to grayscale and apply thresholding (for OCR enhancement)
        gray = cv2.cvtColor(cropped, cv2.COLOR_BGR2GRAY)
        thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]

        # Run OCR on the cropped region
        ocr_results = ocr.ocr(thresh, cls=True)

        for ocr_result in ocr_results[0]:
            bbox, (page_number, ocr_confidence) = ocr_result

            # Ensure extracted text is a valid page number (only digits)
            if page_number.isdigit() and ocr_confidence > best_confidence:
                best_page_number = page_number
                best_confidence = ocr_confidence

        # Add detected text near the bounding box
        cv2.putText(image, f"{best_page_number}", (x1, y1 - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)

# Show image with bounding box
cv2_imshow(image)

# Print the final detected handwritten page number
if best_page_number:
    print(f"Final Detected Handwritten Page Number: {best_page_number} (Confidence: {best_confidence:.2f})")
else:
    print("No valid handwritten page number detected.")

!pip install ultralytics

from ultralytics import YOLO
model = YOLO("/content/drive/MyDrive/yolov8_pagenumber/train2/weights/best.pt")


results = model.predict(source="/content/drive/MyDrive/Yolo v11 page number dataset/test/images/page_117_png_jpg.rf.b414fcfd12503e324b43362c8a518d54.jpg", save=True)

results[0].show()